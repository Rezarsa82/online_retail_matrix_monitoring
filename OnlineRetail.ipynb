{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOVac6hph/khwRCxq2RAtkv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rezarsa82/online_retail_matrix_monitoring/blob/main/OnlineRetail.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I-3NRPwgxKC",
        "outputId": "0b62520c-2b30-487f-c081-da55c7c1ecdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Online Retail.xlsx']\n",
            "Index(['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
            "       'UnitPrice', 'CustomerID', 'Country'],\n",
            "      dtype='object')\n",
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
            "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
            "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/352/online+retail.zip\"\n",
        "\n",
        "r = requests.get(url)\n",
        "zip_file = zipfile.ZipFile(BytesIO(r.content))\n",
        "\n",
        "print(zip_file.namelist())  # ['Online Retail.xlsx']\n",
        "\n",
        "excel_file = zip_file.open(\"Online Retail.xlsx\")\n",
        "df = pd.read_excel(excel_file)\n",
        "\n",
        "print(df.columns)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isna().sum())\n",
        "df = df.dropna()\n",
        "print(df.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJcVXKOthQK7",
        "outputId": "745ec9fb-589e-4428-b2a1-96a099dca928"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InvoiceNo           0\n",
            "StockCode           0\n",
            "Description      1454\n",
            "Quantity            0\n",
            "InvoiceDate         0\n",
            "UnitPrice           0\n",
            "CustomerID     135080\n",
            "Country             0\n",
            "dtype: int64\n",
            "InvoiceNo      0\n",
            "StockCode      0\n",
            "Description    0\n",
            "Quantity       0\n",
            "InvoiceDate    0\n",
            "UnitPrice      0\n",
            "CustomerID     0\n",
            "Country        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"Quantity\"] > 0]\n",
        "print((df[\"Quantity\"] <= 0).sum())\n",
        "num_cancelled = df[df[\"InvoiceNo\"].astype(str).str.startswith(\"C\")].shape[0]\n",
        "print(\"Cannelled:\", num_cancelled)\n",
        "df_sorted = df.sort_values('InvoiceDate')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2QjvzIEhzj-",
        "outputId": "07b51a34-4461-482e-bc08-4bda0e6a66d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Cannelled: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item_transaction_matrix = df_sorted.groupby(['InvoiceNo', 'StockCode'])['Quantity'].sum().unstack().fillna(0)\n",
        "\n",
        "item_transaction_matrix[item_transaction_matrix > 0] = 1\n",
        "\n",
        "print(item_transaction_matrix.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g6IOiS_h8mk",
        "outputId": "fccbfbfb-ce84-4bbc-c984-4ee70dcb96b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StockCode  10002  10080  10120  10125  10133  10135  11001  15030  15034  \\\n",
            "InvoiceNo                                                                  \n",
            "536365       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "536366       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "536367       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "536368       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "536369       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "\n",
            "StockCode  15036  ...  90214V  90214W  90214Y  90214Z  BANK CHARGES   C2  DOT  \\\n",
            "InvoiceNo         ...                                                           \n",
            "536365       0.0  ...     0.0     0.0     0.0     0.0           0.0  0.0  0.0   \n",
            "536366       0.0  ...     0.0     0.0     0.0     0.0           0.0  0.0  0.0   \n",
            "536367       0.0  ...     0.0     0.0     0.0     0.0           0.0  0.0  0.0   \n",
            "536368       0.0  ...     0.0     0.0     0.0     0.0           0.0  0.0  0.0   \n",
            "536369       0.0  ...     0.0     0.0     0.0     0.0           0.0  0.0  0.0   \n",
            "\n",
            "StockCode    M  PADS  POST  \n",
            "InvoiceNo                   \n",
            "536365     0.0   0.0   0.0  \n",
            "536366     0.0   0.0   0.0  \n",
            "536367     0.0   0.0   0.0  \n",
            "536368     0.0   0.0   0.0  \n",
            "536369     0.0   0.0   0.0  \n",
            "\n",
            "[5 rows x 3665 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_invoices = random.sample(list(item_transaction_matrix.index), 5)\n",
        "\n",
        "for invoice in random_invoices:\n",
        "    purchased_items = item_transaction_matrix.loc[invoice][item_transaction_matrix.loc[invoice] == 1]\n",
        "    print(f\"ّInvoice {invoice}: {len(purchased_items)} Products\")\n",
        "    if len(purchased_items) > 0:\n",
        "        print(f\"   Products: {list(purchased_items.index[:5])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkyUa60ekdBh",
        "outputId": "b49de6ba-d1f4-4f21-834a-75c8ca933fd3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ّInvoice 562599: 10 Products\n",
            "   Products: [22361, 22362, 22962, 22963, 23012]\n",
            "ّInvoice 563907: 7 Products\n",
            "   Products: [22169, 22720, 23298, 47566, 71477]\n",
            "ّInvoice 579099: 29 Products\n",
            "   Products: [16046, 20674, 20675, 20677, 21034]\n",
            "ّInvoice 564862: 1 Products\n",
            "   Products: ['POST']\n",
            "ّInvoice 555415: 4 Products\n",
            "   Products: [21340, 22178, 22427, 22784]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 500\n",
        "batches = []\n",
        "\n",
        "for i in range(0, len(item_transaction_matrix), batch_size):\n",
        "    batch_matrix = item_transaction_matrix.iloc[i : i + batch_size]\n",
        "    batches.append(batch_matrix)\n",
        "\n",
        "print(f\"Total batches: {len(batches)}\")\n",
        "print(f\"First batch shape: {batches[0].shape}\")\n",
        "print(f\"Last batch shape: {batches[-1].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LewoGm5akwUz",
        "outputId": "f1e715fe-8e9c-429a-be03-747d235143f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total batches: 38\n",
            "First batch shape: (500, 3665)\n",
            "Last batch shape: (36, 3665)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FrequentDirections:\n",
        "    def __init__(self, ell):\n",
        "        self.ell = ell\n",
        "        self.d = None\n",
        "        self.sketch = None\n",
        "        self.next_row = 0\n",
        "\n",
        "    def fit(self, data_stream):\n",
        "        for row in data_stream:\n",
        "            self._update(row)\n",
        "\n",
        "    def _is_full(self):\n",
        "        return self.next_row >= self.ell\n",
        "\n",
        "    def _update(self, row):\n",
        "        row = np.array(row)\n",
        "\n",
        "        if self.d is None:\n",
        "            self.d = len(row)\n",
        "            self.sketch = np.zeros((self.ell, self.d))\n",
        "            self.next_row = 0\n",
        "\n",
        "        if self._is_full():\n",
        "            self._compress()\n",
        "\n",
        "        self.sketch[self.next_row] = row\n",
        "        self.next_row += 1\n",
        "\n",
        "    def _compress(self):\n",
        "        U, sigma, Vt = np.linalg.svd(self.sketch, full_matrices=False)\n",
        "\n",
        "        delta_sq = sigma[self.ell // 2 - 1] ** 2\n",
        "\n",
        "        new_sigma_sq = np.maximum(sigma ** 2 - delta_sq, 0)\n",
        "        new_sigma = np.sqrt(new_sigma_sq)\n",
        "\n",
        "        self.sketch = np.diag(new_sigma) @ Vt\n",
        "\n",
        "        self.next_row = self.ell // 2\n",
        "\n",
        "    def get_sketch(self):\n",
        "        return self.sketch\n"
      ],
      "metadata": {
        "id": "Oc9vG1gZlq0-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def test_fd_basic_shape():\n",
        "    print(\"Test 1: Basic shape check\")\n",
        "    data = np.random.randn(100, 10)\n",
        "    fd = FrequentDirections(ell=5)\n",
        "    fd.fit(data)\n",
        "    B = fd.get_sketch()\n",
        "\n",
        "    assert B.shape == (5, 10), f\"Expected (5, 10), got {B.shape}\"\n",
        "    print(\"✅ Passed: Output shape is correct.\")\n",
        "\n",
        "\n",
        "def test_fd_reduces_dimension():\n",
        "    print(\"Test 2: Dimensionality reduction consistency\")\n",
        "    data = np.random.randn(200, 20)\n",
        "    ell = 8\n",
        "    fd = FrequentDirections(ell)\n",
        "    fd.fit(data)\n",
        "    B = fd.get_sketch()\n",
        "\n",
        "    rank_B = np.linalg.matrix_rank(B)\n",
        "    assert rank_B <= ell, f\"Rank too high: {rank_B} > {ell}\"\n",
        "    print(\"✅ Passed: Sketch rank is within expected limit.\")\n",
        "\n",
        "\n",
        "def test_fd_variance_preservation():\n",
        "    print(\"Test 3: Variance preservation (A^T A ≈ B^T B)\")\n",
        "    np.random.seed(0)\n",
        "    data = np.random.randn(500, 50)\n",
        "    ell = 20\n",
        "    fd = FrequentDirections(ell)\n",
        "    fd.fit(data)\n",
        "    B = fd.get_sketch()\n",
        "\n",
        "    A_cov = data.T @ data\n",
        "    B_cov = B.T @ B\n",
        "    diff = np.linalg.norm(A_cov - B_cov, 'fro')\n",
        "\n",
        "    print(f\"‣ Frobenius norm difference: {diff:.4f}\")\n",
        "    assert diff < np.linalg.norm(A_cov, 'fro'), \"Sketch too inaccurate!\"\n",
        "    print(\"✅ Passed: Sketch preserves variance reasonably.\")\n",
        "\n",
        "\n",
        "def test_fd_on_stream():\n",
        "    print(\"Test 4: Streaming consistency\")\n",
        "    np.random.seed(42)\n",
        "    data = np.random.randn(1000, 30)\n",
        "    fd = FrequentDirections(ell=15)\n",
        "\n",
        "    for i in range(0, len(data), 10):\n",
        "        fd.fit(data[i:i+10])\n",
        "\n",
        "    B = fd.get_sketch()\n",
        "    assert not np.allclose(B, 0), \"Sketch should not be all zeros.\"\n",
        "    print(\"✅ Passed: Streaming updates work correctly.\")\n",
        "\n",
        "\n",
        "def test_fd_repeatability():\n",
        "    print(\"Test 5: Determinism\")\n",
        "    np.random.seed(123)\n",
        "    data = np.random.randn(300, 20)\n",
        "    ell = 10\n",
        "\n",
        "    fd1 = FrequentDirections(ell)\n",
        "    fd1.fit(data)\n",
        "    B1 = fd1.get_sketch()\n",
        "\n",
        "    fd2 = FrequentDirections(ell)\n",
        "    fd2.fit(data)\n",
        "    B2 = fd2.get_sketch()\n",
        "\n",
        "    assert np.allclose(B1, B2), \"Frequent Directions should be deterministic.\"\n",
        "    print(\"✅ Passed: Algorithm is deterministic.\")\n",
        "\n",
        "def test_fd_theoretical_bound():\n",
        "    print(\"Test 6: Theoretical FD guarantee check\")\n",
        "\n",
        "    np.random.seed(123)\n",
        "    n, d = 500, 50\n",
        "    ell = 20\n",
        "    data = np.random.randn(n, d)\n",
        "\n",
        "    fd = FrequentDirections(ell)\n",
        "    fd.fit(data)\n",
        "    B = fd.get_sketch()\n",
        "\n",
        "    A_cov = data.T @ data\n",
        "    B_cov = B.T @ B\n",
        "\n",
        "    A_fro_sq = np.linalg.norm(data, 'fro') ** 2\n",
        "\n",
        "    spectral_diff = np.linalg.norm(A_cov - B_cov, 2)\n",
        "\n",
        "    bound = A_fro_sq / ell\n",
        "\n",
        "    print(f\"‣ Spectral diff: {spectral_diff:.4f}\")\n",
        "    print(f\"‣ Theoretical bound: {bound:.4f}\")\n",
        "\n",
        "    assert spectral_diff <= bound * 1.2, (\n",
        "        f\"❌ Theoretical guarantee violated: diff={spectral_diff:.4f} > bound={bound:.4f}\"\n",
        "    )\n",
        "    print(\"✅ Passed: Theoretical FD guarantee approximately holds.\")\n",
        "\n",
        "test_fd_basic_shape()\n",
        "test_fd_reduces_dimension()\n",
        "test_fd_variance_preservation()\n",
        "test_fd_on_stream()\n",
        "test_fd_repeatability()\n",
        "test_fd_theoretical_bound()\n",
        "print(\"\\nAll tests passed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA0PzbDbz1lI",
        "outputId": "02d18760-7e6a-43ac-e75e-43244ba09a80"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1: Basic shape check\n",
            "✅ Passed: Output shape is correct.\n",
            "Test 2: Dimensionality reduction consistency\n",
            "✅ Passed: Sketch rank is within expected limit.\n",
            "Test 3: Variance preservation (A^T A ≈ B^T B)\n",
            "‣ Frobenius norm difference: 3525.2132\n",
            "✅ Passed: Sketch preserves variance reasonably.\n",
            "Test 4: Streaming consistency\n",
            "✅ Passed: Streaming updates work correctly.\n",
            "Test 5: Determinism\n",
            "✅ Passed: Algorithm is deterministic.\n",
            "Test 6: Theoretical FD guarantee check\n",
            "‣ Spectral diff: 830.0659\n",
            "‣ Theoretical bound: 1240.3073\n",
            "✅ Passed: Theoretical FD guarantee approximately holds.\n",
            "\n",
            "All tests passed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IPCA:\n",
        "    def __init__(self, n_components, amnesic=1.0, continuity_correction=True):\n",
        "        self.n_components = n_components\n",
        "        self.amnesic = amnesic\n",
        "        self.continuity_correction = continuity_correction\n",
        "\n",
        "        self.mean_ = None\n",
        "        self.components_ = None\n",
        "        self.explained_variance_ = None\n",
        "        self.explained_variance_ratio_ = None\n",
        "        self.n_samples_seen_ = 0\n",
        "        self.svd_ = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = np.array(X)\n",
        "        if len(X.shape) == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            self.partial_fit(X[i:i+1])\n",
        "        return self\n",
        "\n",
        "    def partial_fit(self, X):\n",
        "        X = np.array(X)\n",
        "        if len(X.shape) == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if self.mean_ is None:\n",
        "            self.mean_ = np.zeros(n_features)\n",
        "            self.components_ = np.eye(n_features)[:self.n_components]\n",
        "            self.explained_variance_ = np.zeros(self.n_components)\n",
        "            self.svd_ = {\n",
        "                'U': np.eye(n_features, self.n_components),\n",
        "                'sigma': np.zeros(self.n_components),\n",
        "                'Vt': np.eye(self.n_components, n_features)\n",
        "            }\n",
        "\n",
        "        old_mean = self.mean_.copy()\n",
        "        self.mean_ = (self.n_samples_seen_ * self.mean_ + np.sum(X, axis=0)) / (self.n_samples_seen_ + n_samples)\n",
        "\n",
        "        if self.continuity_correction and self.n_samples_seen_ > 0:\n",
        "            correction = np.sqrt(self.n_samples_seen_ * n_samples / (self.n_samples_seen_ + n_samples)) * (old_mean - self.mean_)\n",
        "            X_centered = X - self.mean_ + correction\n",
        "        else:\n",
        "            X_centered = X - self.mean_\n",
        "\n",
        "        self._update_svd(X_centered)\n",
        "\n",
        "        self.n_samples_seen_ += n_samples\n",
        "        return self\n",
        "\n",
        "    def _update_svd(self, X_centered):\n",
        "        n_samples, n_features = X_centered.shape\n",
        "\n",
        "        if self.n_samples_seen_ == 0:\n",
        "            U, sigma, Vt = np.linalg.svd(X_centered, full_matrices=False)\n",
        "            self.svd_ = {\n",
        "                'U': U[:, :self.n_components],\n",
        "                'sigma': sigma[:self.n_components],\n",
        "                'Vt': Vt[:self.n_components]\n",
        "            }\n",
        "        else:\n",
        "            U_old = self.svd_['U']\n",
        "            sigma_old = self.svd_['sigma']\n",
        "            Vt_old = self.svd_['Vt']\n",
        "\n",
        "            if self.amnesic != 1.0 and self.n_samples_seen_ > 0:\n",
        "                weight = (self.n_samples_seen_ / (self.n_samples_seen_ + n_samples)) ** self.amnesic\n",
        "                sigma_old = sigma_old * weight\n",
        "\n",
        "            augmented_matrix = np.vstack([\n",
        "                np.diag(sigma_old) @ Vt_old,\n",
        "                X_centered\n",
        "            ])\n",
        "\n",
        "            U_aug, sigma_aug, Vt_aug = np.linalg.svd(augmented_matrix, full_matrices=False)\n",
        "\n",
        "            self.svd_ = {\n",
        "                'U': U_aug[:, :self.n_components],\n",
        "                'sigma': sigma_aug[:self.n_components],\n",
        "                'Vt': Vt_aug[:self.n_components]\n",
        "            }\n",
        "\n",
        "        self.components_ = self.svd_['Vt']\n",
        "        self.explained_variance_ = (self.svd_['sigma'] ** 2) / max(1, self.n_samples_seen_)\n",
        "\n",
        "        total_variance = np.sum(self.explained_variance_)\n",
        "        if total_variance > 0:\n",
        "            self.explained_variance_ratio_ = self.explained_variance_ / total_variance\n",
        "        else:\n",
        "            self.explained_variance_ratio_ = self.explained_variance_\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.mean_ is not None:\n",
        "            X_centered = X - self.mean_\n",
        "            return X_centered @ self.components_.T\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "        if self.mean_ is not None:\n",
        "            return X @ self.components_ + self.mean_\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def get_sketch(self):\n",
        "        return {\n",
        "            'components': self.components_,\n",
        "            'explained_variance': self.explained_variance_,\n",
        "            'mean': self.mean_,\n",
        "            'n_samples': self.n_samples_seen_\n",
        "        }"
      ],
      "metadata": {
        "id": "UYzyH0NE3CSt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_ipca_initialization():\n",
        "    print(\"Test 1: Initialization check\")\n",
        "    ipca = IPCA(n_components=3)\n",
        "\n",
        "    assert ipca.n_components == 3, f\"Expected 3, got {ipca.n_components}\"\n",
        "    assert ipca.mean_ is None, \"Mean should be None before fitting\"\n",
        "    assert ipca.components_ is None, \"Components should be None before fitting\"\n",
        "    assert ipca.n_samples_seen_ == 0, f\"Expected 0 samples, got {ipca.n_samples_seen_}\"\n",
        "    print(\"✅ Passed: Initialization is correct.\")\n",
        "\n",
        "def test_ipca_basic_shape():\n",
        "    print(\"Test 2: Basic shape check after fitting\")\n",
        "    data = np.random.randn(100, 10)\n",
        "    ipca = IPCA(n_components=5)\n",
        "    ipca.fit(data)\n",
        "\n",
        "    assert ipca.components_.shape == (5, 10), f\"Expected (5, 10), got {ipca.components_.shape}\"\n",
        "    assert ipca.mean_.shape == (10,), f\"Expected (10,), got {ipca.mean_.shape}\"\n",
        "    assert ipca.n_samples_seen_ == 100, f\"Expected 100 samples, got {ipca.n_samples_seen_}\"\n",
        "    print(\"✅ Passed: Output shapes are correct.\")\n",
        "\n",
        "def test_ipca_transform_consistency():\n",
        "    print(\"Test 3: Transform and inverse transform consistency\")\n",
        "    np.random.seed(42)\n",
        "    data = np.random.randn(50, 8)\n",
        "    ipca = IPCA(n_components=4)\n",
        "    ipca.fit(data)\n",
        "\n",
        "    X_transformed = ipca.transform(data)\n",
        "    X_reconstructed = ipca.inverse_transform(X_transformed)\n",
        "\n",
        "    assert X_transformed.shape == (50, 4), f\"Expected (50, 4), got {X_transformed.shape}\"\n",
        "    assert X_reconstructed.shape == (50, 8), f\"Expected (50, 8), got {X_reconstructed.shape}\"\n",
        "\n",
        "    reconstruction_error = np.mean((data - X_reconstructed) ** 2)\n",
        "    print(f\"‣ Reconstruction error: {reconstruction_error:.6f}\")\n",
        "    assert reconstruction_error < 1.0, \"Reconstruction error too high!\"\n",
        "    print(\"✅ Passed: Transform and inverse transform work correctly.\")\n",
        "\n",
        "def test_ipca_orthogonality():\n",
        "    print(\"Test 4: Components orthogonality check\")\n",
        "    data = np.random.randn(200, 15)\n",
        "    ipca = IPCA(n_components=6)\n",
        "    ipca.fit(data)\n",
        "\n",
        "    dot_products = ipca.components_ @ ipca.components_.T\n",
        "    identity_matrix = np.eye(6)\n",
        "\n",
        "    max_deviation = np.max(np.abs(dot_products - identity_matrix))\n",
        "    print(f\"‣ Maximum deviation from orthogonality: {max_deviation:.6f}\")\n",
        "    assert max_deviation < 1e-10, \"Components are not orthogonal!\"\n",
        "    print(\"✅ Passed: Components are orthogonal.\")\n",
        "\n",
        "def test_ipca_unit_norm():\n",
        "    print(\"Test 5: Components unit norm check\")\n",
        "    data = np.random.randn(150, 12)\n",
        "    ipca = IPCA(n_components=5)\n",
        "    ipca.fit(data)\n",
        "\n",
        "    norms = np.linalg.norm(ipca.components_, axis=1)\n",
        "    norm_errors = np.abs(norms - 1.0)\n",
        "\n",
        "    max_norm_error = np.max(norm_errors)\n",
        "    print(f\"‣ Maximum norm error: {max_norm_error:.6f}\")\n",
        "    assert max_norm_error < 1e-10, \"Components don't have unit norm!\"\n",
        "    print(\"✅ Passed: All components have unit norm.\")\n",
        "\n",
        "def test_ipca_incremental_learning():\n",
        "    print(\"Test 6: Incremental learning consistency\")\n",
        "    np.random.seed(123)\n",
        "    data = np.random.randn(300, 10)\n",
        "\n",
        "    ipca_batch = IPCA(n_components=4)\n",
        "    ipca_batch.fit(data)\n",
        "\n",
        "    ipca_incremental = IPCA(n_components=4)\n",
        "    batch_size = 30\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        ipca_incremental.partial_fit(data[i:i+batch_size])\n",
        "\n",
        "    assert ipca_incremental.n_samples_seen_ == ipca_batch.n_samples_seen_, \"Sample counts don't match\"\n",
        "    assert ipca_incremental.components_.shape == ipca_batch.components_.shape, \"Component shapes don't match\"\n",
        "\n",
        "    similarity = np.abs(ipca_incremental.components_ @ ipca_batch.components_.T)\n",
        "    min_similarity = np.min(np.diag(similarity))\n",
        "    print(f\"‣ Minimum component similarity: {min_similarity:.6f}\")\n",
        "    print(\"✅ Passed: Incremental learning matches batch learning.\")\n",
        "\n",
        "def test_ipca_explained_variance():\n",
        "    print(\"Test 7: Explained variance properties\")\n",
        "    data = np.random.randn(200, 8)\n",
        "    ipca = IPCA(n_components=3)\n",
        "    ipca.fit(data)\n",
        "\n",
        "    ratios = ipca.explained_variance_ratio_\n",
        "\n",
        "    assert np.all(ratios >= 0), \"Negative explained variance ratio!\"\n",
        "    assert np.all(ratios <= 1), \"Explained variance ratio > 1!\"\n",
        "    assert np.sum(ratios) <= 1.0 + 1e-10, \"Sum of ratios > 1!\"\n",
        "\n",
        "    for i in range(1, len(ratios)):\n",
        "        assert ratios[i] <= ratios[i-1] + 1e-10, \"Variance ratios not in descending order!\"\n",
        "\n",
        "    print(f\"‣ Explained variance ratios: {ratios}\")\n",
        "    print(\"✅ Passed: Explained variance properties are correct.\")\n",
        "\n",
        "def test_ipca_amnesic_learning():\n",
        "    print(\"Test 8: Amnesic learning with different parameters\")\n",
        "    data = np.random.randn(100, 6)\n",
        "\n",
        "    amnesic_values = [0.0, 0.5, 1.0, 2.0]\n",
        "    components_list = []\n",
        "\n",
        "    for amnesic in amnesic_values:\n",
        "        ipca = IPCA(n_components=3, amnesic=amnesic)\n",
        "        ipca.fit(data)\n",
        "        components_list.append(ipca.components_)\n",
        "        assert ipca.components_.shape == (3, 6), f\"Wrong shape for amnesic={amnesic}\"\n",
        "\n",
        "    print(\"‣ All amnesic values produced valid results\")\n",
        "    print(\"✅ Passed: Amnesic learning works with different parameters.\")\n",
        "\n",
        "def test_ipca_continuity_correction():\n",
        "    print(\"Test 9: Continuity correction\")\n",
        "    np.random.seed(42)\n",
        "    data = np.random.randn(80, 7)\n",
        "\n",
        "    ipca_with_cc = IPCA(n_components=3, continuity_correction=True)\n",
        "    ipca_without_cc = IPCA(n_components=3, continuity_correction=False)\n",
        "\n",
        "    batch_size = 10\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        ipca_with_cc.partial_fit(data[i:i+batch_size])\n",
        "        ipca_without_cc.partial_fit(data[i:i+batch_size])\n",
        "\n",
        "    assert ipca_with_cc.components_.shape == (3, 7), \"Wrong shape with continuity correction\"\n",
        "    assert ipca_without_cc.components_.shape == (3, 7), \"Wrong shape without continuity correction\"\n",
        "    print(\"✅ Passed: Continuity correction works correctly.\")\n",
        "\n",
        "\n",
        "test_ipca_initialization()\n",
        "test_ipca_basic_shape()\n",
        "test_ipca_transform_consistency()\n",
        "test_ipca_orthogonality()\n",
        "test_ipca_unit_norm()\n",
        "test_ipca_incremental_learning()\n",
        "test_ipca_explained_variance()\n",
        "test_ipca_amnesic_learning()\n",
        "test_ipca_continuity_correction()\n",
        "\n",
        "print(\"\\nAll IPCA tests passed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q12Tf1Lr7TPP",
        "outputId": "d9016561-1719-4e7c-ce8f-0592827aed36"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1: Initialization check\n",
            "✅ Passed: Initialization is correct.\n",
            "Test 2: Basic shape check after fitting\n",
            "✅ Passed: Output shapes are correct.\n",
            "Test 3: Transform and inverse transform consistency\n",
            "‣ Reconstruction error: 0.300850\n",
            "✅ Passed: Transform and inverse transform work correctly.\n",
            "Test 4: Components orthogonality check\n",
            "‣ Maximum deviation from orthogonality: 0.000000\n",
            "✅ Passed: Components are orthogonal.\n",
            "Test 5: Components unit norm check\n",
            "‣ Maximum norm error: 0.000000\n",
            "✅ Passed: All components have unit norm.\n",
            "Test 6: Incremental learning consistency\n",
            "‣ Minimum component similarity: 0.482159\n",
            "✅ Passed: Incremental learning matches batch learning.\n",
            "Test 7: Explained variance properties\n",
            "‣ Explained variance ratios: [0.37037128 0.36038381 0.26924491]\n",
            "✅ Passed: Explained variance properties are correct.\n",
            "Test 8: Amnesic learning with different parameters\n",
            "‣ All amnesic values produced valid results\n",
            "✅ Passed: Amnesic learning works with different parameters.\n",
            "Test 9: Continuity correction\n",
            "✅ Passed: Continuity correction works correctly.\n",
            "\n",
            "All IPCA tests passed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianRandomProjection:\n",
        "    def __init__(self, n_components=2, random_state=None):\n",
        "        self.n_components = n_components\n",
        "        self.random_state = random_state\n",
        "        self.random_matrix_ = None\n",
        "        self.n_features_ = None\n",
        "\n",
        "    def _generate_random_matrix(self, n_features):\n",
        "      rng = np.random.RandomState(self.random_state)\n",
        "      random_matrix = rng.randn(n_features, self.n_components) / np.sqrt(self.n_components)\n",
        "      return random_matrix\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = np.array(X)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if self.n_components > n_features:\n",
        "            raise ValueError(f\"n_components ({self.n_components}) must be <= n_features ({n_features})\")\n",
        "\n",
        "        self.n_features_ = n_features\n",
        "        self.random_matrix_ = self._generate_random_matrix(n_features)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.random_matrix_ is None:\n",
        "            raise ValueError(\"Model not fitted. Call fit first.\")\n",
        "\n",
        "        X = np.array(X)\n",
        "        if X.shape[1] != self.n_features_:\n",
        "            raise ValueError(f\"Expected {self.n_features_} features, got {X.shape[1]}\")\n",
        "\n",
        "        return X @ self.random_matrix_\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "      if self.random_matrix_ is None:\n",
        "          raise ValueError(\"Model not fitted. Call fit first.\")\n",
        "\n",
        "      X = np.array(X)\n",
        "      random_matrix_pinv = np.linalg.pinv(self.random_matrix_)\n",
        "      return X @ random_matrix_pinv\n",
        "\n",
        "\n",
        "    def get_params(self):\n",
        "        return {\n",
        "            'random_matrix': self.random_matrix_,\n",
        "            'n_features': self.n_features_,\n",
        "            'n_components': self.n_components\n",
        "        }"
      ],
      "metadata": {
        "id": "wVMQdXt37hw3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_grp_basic_shape():\n",
        "    print(\"Test 1: Basic shape check\")\n",
        "    data = np.random.randn(100, 20)\n",
        "    grp = GaussianRandomProjection(n_components=5, random_state=42)\n",
        "    grp.fit(data)\n",
        "    X_transformed = grp.transform(data)\n",
        "\n",
        "    assert X_transformed.shape == (100, 5), f\"Expected (100, 5), got {X_transformed.shape}\"\n",
        "    assert grp.random_matrix_.shape == (20, 5), f\"Expected (20, 5), got {grp.random_matrix_.shape}\"\n",
        "    print(\"✅ Passed: Output shape is correct.\")\n",
        "\n",
        "def test_grp_distance_preservation():\n",
        "    print(\"Test 2: Distance preservation check\")\n",
        "    np.random.seed(42)\n",
        "\n",
        "    data = np.array([\n",
        "        [1, 0, 0, 0],\n",
        "        [0, 1, 0, 0],\n",
        "        [0, 0, 1, 0],\n",
        "        [0, 0, 0, 1]\n",
        "    ])\n",
        "\n",
        "    grp = GaussianRandomProjection(n_components=3, random_state=42)\n",
        "    X_reduced = grp.fit_transform(data)\n",
        "\n",
        "    original_distances = np.linalg.norm(data[:, np.newaxis] - data, axis=2)\n",
        "\n",
        "    reduced_distances = np.linalg.norm(X_reduced[:, np.newaxis] - X_reduced, axis=2)\n",
        "\n",
        "    relative_errors = np.abs(original_distances - reduced_distances) / original_distances\n",
        "    mean_relative_error = np.mean(relative_errors[np.triu_indices_from(relative_errors, k=1)])\n",
        "\n",
        "    print(f\"‣ Mean relative distance error: {mean_relative_error:.4f}\")\n",
        "    assert mean_relative_error < 0.5, \"Distance preservation too poor!\"\n",
        "    print(\"✅ Passed: Distances are reasonably preserved.\")\n",
        "\n",
        "def test_grp_reproducibility():\n",
        "    print(\"Test 3: Reproducibility with random_state\")\n",
        "    data = np.random.randn(50, 10)\n",
        "\n",
        "    grp1 = GaussianRandomProjection(n_components=4, random_state=123)\n",
        "    grp2 = GaussianRandomProjection(n_components=4, random_state=123)\n",
        "\n",
        "    X1 = grp1.fit_transform(data)\n",
        "    X2 = grp2.fit_transform(data)\n",
        "\n",
        "    assert np.allclose(X1, X2), \"Results should be identical with same random_state\"\n",
        "    print(\"✅ Passed: Results are reproducible with fixed random_state.\")\n",
        "\n",
        "def test_grp_fit_transform_consistency():\n",
        "    print(\"Test 4: Fit-transform consistency\")\n",
        "    data = np.random.randn(80, 15)\n",
        "    grp = GaussianRandomProjection(n_components=6, random_state=42)\n",
        "\n",
        "    grp.fit(data)\n",
        "    X1 = grp.transform(data)\n",
        "\n",
        "    X2 = grp.fit_transform(data)\n",
        "\n",
        "    assert np.allclose(X1, X2), \"fit+transform should equal fit_transform\"\n",
        "    print(\"✅ Passed: Fit-transform consistency verified.\")\n",
        "\n",
        "def test_grp_error_handling():\n",
        "    print(\"Test 6: Error handling\")\n",
        "\n",
        "    try:\n",
        "        data = np.random.randn(10, 5)\n",
        "        grp = GaussianRandomProjection(n_components=10)\n",
        "        grp.fit(data)\n",
        "        assert False, \"Should have raised ValueError\"\n",
        "    except ValueError:\n",
        "        print(\"‣ Correctly caught n_components > n_features error\")\n",
        "\n",
        "    try:\n",
        "        grp = GaussianRandomProjection(n_components=3)\n",
        "        grp.transform(np.random.randn(5, 4))\n",
        "        assert False, \"Should have raised ValueError\"\n",
        "    except ValueError:\n",
        "        print(\"‣ Correctly caught transform before fit error\")\n",
        "\n",
        "    print(\"✅ Passed: Error handling works correctly.\")\n",
        "\n",
        "def test_grp_different_dimensions():\n",
        "    print(\"Test 7: Performance with different dimensions\")\n",
        "    np.random.seed(42)\n",
        "\n",
        "    dimensions = [(100, 50, 10), (200, 30, 5), (50, 100, 20)]\n",
        "\n",
        "    for n_samples, n_features, n_components in dimensions:\n",
        "        data = np.random.randn(n_samples, n_features)\n",
        "        grp = GaussianRandomProjection(n_components=n_components, random_state=42)\n",
        "\n",
        "        X_reduced = grp.fit_transform(data)\n",
        "        assert X_reduced.shape == (n_samples, n_components), f\"Failed for {n_samples}, {n_features} -> {n_components}\"\n",
        "\n",
        "        assert not np.allclose(X_reduced, 0), \"Output should not be all zeros\"\n",
        "\n",
        "    print(\"‣ All dimension combinations worked correctly\")\n",
        "    print(\"✅ Passed: Works with various dimension configurations.\")\n",
        "\n",
        "test_grp_basic_shape()\n",
        "test_grp_distance_preservation()\n",
        "test_grp_reproducibility()\n",
        "test_grp_fit_transform_consistency()\n",
        "test_grp_error_handling()\n",
        "test_grp_different_dimensions()\n",
        "\n",
        "print(\"\\nAll Gaussian Random Projection tests passed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g655stk2G6MF",
        "outputId": "078e7bc7-c39b-4a21-fd8e-f1d2962e056e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1: Basic shape check\n",
            "✅ Passed: Output shape is correct.\n",
            "Test 2: Distance preservation check\n",
            "‣ Mean relative distance error: 0.4563\n",
            "✅ Passed: Distances are reasonably preserved.\n",
            "Test 3: Reproducibility with random_state\n",
            "✅ Passed: Results are reproducible with fixed random_state.\n",
            "Test 4: Fit-transform consistency\n",
            "✅ Passed: Fit-transform consistency verified.\n",
            "Test 6: Error handling\n",
            "‣ Correctly caught n_components > n_features error\n",
            "‣ Correctly caught transform before fit error\n",
            "✅ Passed: Error handling works correctly.\n",
            "Test 7: Performance with different dimensions\n",
            "‣ All dimension combinations worked correctly\n",
            "✅ Passed: Works with various dimension configurations.\n",
            "\n",
            "All Gaussian Random Projection tests passed successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1475051153.py:30: RuntimeWarning: invalid value encountered in divide\n",
            "  relative_errors = np.abs(original_distances - reduced_distances) / original_distances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grp = GaussianRandomProjection(n_components=5, random_state=0)\n",
        "ipca = IPCA(n_components=5)\n",
        "fd = FrequentDirections(ell=10)"
      ],
      "metadata": {
        "id": "EIpA1U4PHy7A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t, batch in enumerate(batches, start=1):\n",
        "    print(f\"\\n--- Batch {t} ---\")\n",
        "\n",
        "    grp.fit(batch)\n",
        "    X_grp = grp.transform(batch)\n",
        "    print(f\"[Gaussian RP] Shape after projection: {X_grp.shape}\")\n",
        "\n",
        "    ipca.partial_fit(batch)\n",
        "    print(f\"[IPCA] n_samples_seen: {ipca.n_samples_seen_}\")\n",
        "\n",
        "    fd.fit(batch.values)\n",
        "    sketch = fd.get_sketch()\n",
        "    print(f\"[FrequentDirections] Sketch shape: {sketch.shape}\")\n",
        "    print(f\"[FrequentDirections] Sketch norm: {np.linalg.norm(sketch):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwTPcBB6NRKt",
        "outputId": "fb07750a-2aa3-47ad-944d-388e22311995"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Batch 1 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 10.8234\n",
            "\n",
            "--- Batch 2 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 1000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 16.1522\n",
            "\n",
            "--- Batch 3 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 1500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 19.1671\n",
            "\n",
            "--- Batch 4 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 2000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 15.2523\n",
            "\n",
            "--- Batch 5 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 2500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 18.6310\n",
            "\n",
            "--- Batch 6 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 3000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 9.5589\n",
            "\n",
            "--- Batch 7 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 3500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 13.9228\n",
            "\n",
            "--- Batch 8 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 4000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 10.5872\n",
            "\n",
            "--- Batch 9 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 4500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 16.4140\n",
            "\n",
            "--- Batch 10 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 5000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 13.4875\n",
            "\n",
            "--- Batch 11 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 5500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 15.5169\n",
            "\n",
            "--- Batch 12 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 6000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 10.3573\n",
            "\n",
            "--- Batch 13 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 6500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 13.5099\n",
            "\n",
            "--- Batch 14 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 7000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 12.2974\n",
            "\n",
            "--- Batch 15 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 7500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 11.1604\n",
            "\n",
            "--- Batch 16 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 8000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 12.9603\n",
            "\n",
            "--- Batch 17 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 8500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 11.9441\n",
            "\n",
            "--- Batch 18 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 9000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 13.8066\n",
            "\n",
            "--- Batch 19 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 9500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 15.3119\n",
            "\n",
            "--- Batch 20 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 10000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 8.2484\n",
            "\n",
            "--- Batch 21 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 10500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 17.8143\n",
            "\n",
            "--- Batch 22 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 11000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 18.5742\n",
            "\n",
            "--- Batch 23 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 11500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 11.6179\n",
            "\n",
            "--- Batch 24 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 12000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 14.0437\n",
            "\n",
            "--- Batch 25 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 12500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 11.4068\n",
            "\n",
            "--- Batch 26 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 13000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 16.7568\n",
            "\n",
            "--- Batch 27 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 13500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 18.4778\n",
            "\n",
            "--- Batch 28 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 14000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 12.1555\n",
            "\n",
            "--- Batch 29 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 14500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 15.7170\n",
            "\n",
            "--- Batch 30 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 15000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 17.4414\n",
            "\n",
            "--- Batch 31 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 15500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 15.4777\n",
            "\n",
            "--- Batch 32 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 16000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 17.0238\n",
            "\n",
            "--- Batch 33 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 16500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 10.3349\n",
            "\n",
            "--- Batch 34 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 17000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 13.1902\n",
            "\n",
            "--- Batch 35 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 17500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 11.6682\n",
            "\n",
            "--- Batch 36 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 18000\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 11.2686\n",
            "\n",
            "--- Batch 37 ---\n",
            "[Gaussian RP] Shape after projection: (500, 5)\n",
            "[IPCA] n_samples_seen: 18500\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 12.4258\n",
            "\n",
            "--- Batch 38 ---\n",
            "[Gaussian RP] Shape after projection: (36, 5)\n",
            "[IPCA] n_samples_seen: 18536\n",
            "[FrequentDirections] Sketch shape: (10, 3665)\n",
            "[FrequentDirections] Sketch norm: 7.3905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frobenius_norm(X):\n",
        "    return np.linalg.norm(X, 'fro')\n",
        "\n",
        "def reconstruction_error(original, reconstructed):\n",
        "    return np.linalg.norm(original - reconstructed, 'fro') / np.linalg.norm(original, 'fro')\n",
        "\n",
        "results = []\n",
        "\n",
        "\n",
        "n_components = 20\n",
        "ell = 20\n",
        "\n",
        "for batch_idx, batch in enumerate(batches):\n",
        "    X = batch.values.astype(float)\n",
        "\n",
        "    grp = GaussianRandomProjection(n_components=n_components, random_state=42)\n",
        "    X_proj = grp.fit_transform(X)\n",
        "    X_rec = grp.inverse_transform(X_proj)\n",
        "\n",
        "    norm_f = frobenius_norm(X_rec)\n",
        "    err_f = reconstruction_error(X, X_rec)\n",
        "    var_ratio = np.var(X_proj) / np.var(X) if np.var(X) != 0 else 0\n",
        "\n",
        "    results.append({\n",
        "        \"batch\": batch_idx + 1,\n",
        "        \"algorithm\": \"GaussianRandomProjection\",\n",
        "        \"frobenius_norm\": norm_f,\n",
        "        \"explained_variance\": var_ratio,\n",
        "        \"reconstruction_error\": err_f\n",
        "    })\n",
        "\n",
        "    ipca = IPCA(n_components=n_components)\n",
        "    ipca.fit(X)\n",
        "    X_proj = ipca.transform(X)\n",
        "    X_rec = ipca.inverse_transform(X_proj)\n",
        "\n",
        "    norm_f = frobenius_norm(X_rec)\n",
        "    err_f = reconstruction_error(X, X_rec)\n",
        "    var_ratio = np.sum(ipca.explained_variance_ratio_)\n",
        "\n",
        "    results.append({\n",
        "        \"batch\": batch_idx + 1,\n",
        "        \"algorithm\": \"IncrementalPCA\",\n",
        "        \"frobenius_norm\": norm_f,\n",
        "        \"explained_variance\": var_ratio,\n",
        "        \"reconstruction_error\": err_f\n",
        "    })\n",
        "\n",
        "    fd = FrequentDirections(ell=ell)\n",
        "    fd.fit(X)\n",
        "    sketch = fd.get_sketch()\n",
        "\n",
        "    U, s, Vt = np.linalg.svd(sketch, full_matrices=False)\n",
        "\n",
        "    X_proj = X @ Vt.T[:, :len(s)]\n",
        "    X_rec = X_proj @ Vt[:len(s), :]\n",
        "\n",
        "    norm_f = frobenius_norm(X_rec)\n",
        "    err_f = reconstruction_error(X, X_rec)\n",
        "    var_ratio = np.var(X_rec) / np.var(X) if np.var(X) != 0 else 0\n",
        "\n",
        "    results.append({\n",
        "        \"batch\": batch_idx + 1,\n",
        "        \"algorithm\": \"FrequentDirections\",\n",
        "        \"frobenius_norm\": norm_f,\n",
        "        \"explained_variance\": var_ratio,\n",
        "        \"reconstruction_error\": err_f\n",
        "    })\n",
        "\n",
        "    print(f\"Batch {batch_idx+1} processed.\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"Result Head:\\n\")\n",
        "print(results_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixsqjEucTAz5",
        "outputId": "34a350cd-a1e2-4b9d-ab38-9d8c635a7345"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 processed.\n",
            "Batch 2 processed.\n",
            "Batch 3 processed.\n",
            "Batch 4 processed.\n",
            "Batch 5 processed.\n",
            "Batch 6 processed.\n",
            "Batch 7 processed.\n",
            "Batch 8 processed.\n",
            "Batch 9 processed.\n",
            "Batch 10 processed.\n",
            "Batch 11 processed.\n",
            "Batch 12 processed.\n",
            "Batch 13 processed.\n",
            "Batch 14 processed.\n",
            "Batch 15 processed.\n",
            "Batch 16 processed.\n",
            "Batch 17 processed.\n",
            "Batch 18 processed.\n",
            "Batch 19 processed.\n",
            "Batch 20 processed.\n",
            "Batch 21 processed.\n",
            "Batch 22 processed.\n",
            "Batch 23 processed.\n",
            "Batch 24 processed.\n",
            "Batch 25 processed.\n",
            "Batch 26 processed.\n",
            "Batch 27 processed.\n",
            "Batch 28 processed.\n",
            "Batch 29 processed.\n",
            "Batch 30 processed.\n",
            "Batch 31 processed.\n",
            "Batch 32 processed.\n",
            "Batch 33 processed.\n",
            "Batch 34 processed.\n",
            "Batch 35 processed.\n",
            "Batch 36 processed.\n",
            "Batch 37 processed.\n",
            "Batch 38 processed.\n",
            "Result Head:\n",
            "\n",
            "   batch                 algorithm  frobenius_norm  explained_variance  \\\n",
            "0      1  GaussianRandomProjection        7.245388          191.032066   \n",
            "1      1            IncrementalPCA       50.751171            1.000000   \n",
            "2      1        FrequentDirections       34.841866            0.128235   \n",
            "3      2  GaussianRandomProjection        7.349786          191.956620   \n",
            "4      2            IncrementalPCA       49.544467            1.000000   \n",
            "\n",
            "   reconstruction_error  \n",
            "0              0.997170  \n",
            "1              0.850093  \n",
            "2              0.932354  \n",
            "3              0.997149  \n",
            "4              0.860949  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rwrm76oloPe0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}